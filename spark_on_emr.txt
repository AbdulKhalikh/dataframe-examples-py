# Spark setup on EC2 instance (t2.medium)
# ---------------------------------------------
sudo apt-get update
sudo apt-get install openjdk-8-jdk -y
sudo apt-get install git -y
sudo apt install python3-pip -y
export LC_ALL=C
sudo apt install python3-pip

sudo mkdir /usr/local/scala
wget https://downloads.lightbend.com/scala/2.11.8/scala-2.11.8.tgz
tar -xvzf scala-2.11.8.tgz
sudo mv scala-2.11.8 /usr/local/scala
wget https://archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz
tar -xvzf spark-2.4.5-bin-hadoop2.7.tgz
sudo mv spark-2.4.5-bin-hadoop2.7 /usr/local/scala

# Path setup for Spark
# ---------------------------------------------
sudo vi ~/.bashrc

export SCALA_HOME=/usr/local/scala/scala-2.11.8
export PATH=$SCALA_HOME/bin:$PATH
export SPARK_HOME=/usr/local/scala/spark-2.4.5-bin-hadoop2.7
export PATH=$SPARK_HOME/bin:$PATH
export PYSPARK_PYTHON=python3
export PYSPARK_DRIVER_PYTHON=python3

source ~/.bashrc

# Check if spark-submit command is working
spark-submit

# Setting up Git and Code Repo locally
# --------------------------------------------
# Install Git client software in your local system
# Login to Git and create repo
# Git clone, checkout and pull locally
git clone <repo_url>
git checkput
git pull
# Add .gitignore file inside
# Create a project in PyCharm from that folder
# Add the code inside
# Git add, commit and push
git add .
git commit -a -m "initial commit"
git push origin master


# Setting up Git and Code Repo locally
# --------------------------------------------
# Git clone, checkout and pull locally
git clone <repo_url>
cd <project_dir>
git checkput
git pull
# Install required libraries
sudo pip3 install -r requirements.txt
export PYTHONPATH="$PWD"
echo  $PYTHONPATH

spark-submit --packages "" rdd/test.py
